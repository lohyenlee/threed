{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecb11ee-46a8-4c24-a210-aa00a3d9c66f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notes on choosing camera position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb9d44-dce9-4580-83fe-7114e9144097",
   "metadata": {},
   "source": [
    "$\\newcommand{\\abs}[1]{\\left\\vert #1 \\right\\vert}$\n",
    "$\\newcommand{\\magn}[1]{\\left\\Vert #1 \\right\\Vert}$\n",
    "\n",
    "$\\newcommand{\\vec}[1]{\\underline{\\mathbf{#1}}}$\n",
    "$\\newcommand{\\mat}[1]{\\underline{\\underline{\\mathbf{#1}}}}$\n",
    "\n",
    "$\\newcommand{\\JJJ}{\\mat{J}}$\n",
    "$\\newcommand{\\bbb}{\\vec{b}}$\n",
    "$\\newcommand{\\ccc}{\\vec{c}}$\n",
    "$\\newcommand{\\rrr}{\\vec{r}}$\n",
    "$\\newcommand{\\uuu}{\\vec{u}}$\n",
    "$\\newcommand{\\vvv}{\\vec{v}}$\n",
    "$\\newcommand{\\beq}{\\qquad\\begin{align}}$\n",
    "$\\newcommand{\\eeq}{\\end{align}}$\n",
    "\n",
    "The `threed` package does the following calculations behind the scenes.\n",
    "\n",
    "**Back vector.**\n",
    "Given an elevation $\\alpha=\\frac{\\pi}{2}-\\theta$ (measured in radians upwards from the horizontal) and an azimuth angle $\\phi$ (measured in radians counterclockwise from the $+x$ axis), calculate the unit vector in this direction,\n",
    "\n",
    "$\\qquad$$\\bbb = (\\cos\\alpha\\cos\\phi, \\cos\\alpha\\sin\\phi, \\sin\\alpha)$.\n",
    "\n",
    "In the context of camera orientation, this unit vector defines the camera's *back* vector, which represents the direction in which light travels, which points *opposite* to the direction the camera is facing.  For example, if $\\alpha=0$ and $\\phi=0$, then $\\bbb=(1,0,0)$, so the camera is looking in the $-x$ direction.  If $\\alpha=90^\\circ$, then $\\bbb=(0,0,1)$, so the camera is looking directly downward along the $-z$ direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b5431a-8f71-4e46-97d9-43d89bbc6dea",
   "metadata": {},
   "source": [
    "**Camera orientation**.  Given an elevation $\\alpha$, azimuth $\\phi$, and *vertical* vector $\\vvv$, `threed.chooseCameraOrientation (e, a, up=[0., 0., 1.])` returns a 3x3 unimodular orthogonal matrix $\\JJJ=(\\bbb,\\rrr,\\uuu)$ whose column vectors are the *right*, *up*, and *back* vectors that define camera space, calculated as follows:\n",
    "$\\newcommand{\\abs}[1]{\\left\\Vert #1 \\right\\Vert}$\n",
    "\n",
    "$\\beq\n",
    "\\bbb &:= \\bbb / \\magn{ \\bbb } \\\\\n",
    "\\rrr &:= \\vvv \\times \\ccc / \\magn{ \\vvv \\times \\ccc } \\\\\n",
    "\\uuu &:= \\bbb \\times \\rrr / \\magn{ \\bbb \\times \\rrr } \\\\\n",
    "\\eeq$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95fc8b-37bf-42fc-848b-1c076c912506",
   "metadata": {},
   "source": [
    "**Camera position**.  Some of the calculations below are implemented in `threed.chooseCameraPosition (e, a, up=[0., 0., 1.])`.  Given the objects in a scene, `threed` tries to find a set of points that must lie within view of the camera.  At the moment, it does so by compiling a list of the positions of each Mesh.  (This is not foolproof because a sphere of radius 1 extends 1 unit in each direction beyond its nominal position.)  These points, $\\rrr_n$, are in world coordinates.  The points are transformed to camera space: $\\uuu_n = \\JJJ ~ \\rrr_n$.  (Note that the NumPy implementation of this equation looks different due to conventions.)  The coordinates of the points are unpacked: $\\uuu_n = (u_n, v_n, w_n)$.  The corners of the bounding box in camera space are calculated:\n",
    "\n",
    "$\\beq\n",
    "u_\\mathrm{min} &= \\min_n (u_n)  &v_\\mathrm{min} &= \\min_n (v_n)  &w_\\mathrm{min} &= \\min_n (w_n) \\\\\n",
    "u_\\mathrm{max} &= \\max_n (u_n)  &v_\\mathrm{max} &= \\max_n (v_n)  &w_\\mathrm{max} &= \\max_n (w_n) .\n",
    "\\eeq$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49935a6-7482-4a49-b5a7-626c1e724652",
   "metadata": {},
   "source": [
    "The camera's target position is chosen to be the center of the bounding box:\n",
    "\n",
    "$\\beq\n",
    "\\uuu_\\mathrm{target} &= \\left(\n",
    "\\frac{u_\\mathrm{min}+u_\\mathrm{max}}{2},\n",
    "\\frac{v_\\mathrm{min}+v_\\mathrm{max}}{2},\n",
    "\\frac{w_\\mathrm{min}+w_\\mathrm{max}}{2}\n",
    "\\right)\n",
    "\\eeq$\n",
    "$\\beq\n",
    "\\rrr_\\mathrm{target} &= \\JJJ^{-1} ~ \\uuu_\\mathrm{target}.\n",
    "\\eeq$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b39a301-4230-416d-a2b8-96474e308a56",
   "metadata": {},
   "source": [
    "For simplicity, consider the *front* corners of the bounding box.  That is, consider the rectangle \n",
    "\n",
    "$\\beq\n",
    "u &\\in [u_\\mathrm{min},u_\\mathrm{max}] \\\\\n",
    "v &\\in [v_\\mathrm{min},v_\\mathrm{max}] \\\\\n",
    "w &= w_\\mathrm{\\max}.\n",
    "\\eeq$\n",
    "\n",
    "We are given the vertical field-of-view of the camera $\\beta$ (the angle between the top and bottom viewing directions, typically $50^\\circ$) and the aspect ratio of the camera's viewport, $\\gamma = Y/X$ (typically $4/3$).\n",
    "From trigonometry, in order to capture the left and right sides of the rectangle, the cameraman must \"step back\" from the rectangle by a distance \n",
    "\n",
    "$\\beq\n",
    "w_1 &= \\abs{u_\\mathrm{max} - u_\\mathrm{min}} / \\left( 2 \\gamma \\tan \\frac{\\beta}{2} \\right) \\\\\n",
    "w_2 &= \\abs{v_\\mathrm{max} - v_\\mathrm{min}} / \\left( 2 \\tan \\frac{\\beta}{2} \\right) .\n",
    "\\eeq$\n",
    " \n",
    "The correct step-back distance is the larger of these two: $w_0 = \\max(w_1, w_2)$.  Thus, to find the correct position of the camera, start at the target position and step back a distance $w_0 + \\frac{w_\\mathrm{\\max} - w_\\mathrm{\\min}}{2}$ along the camera's *back* direction:\n",
    "\n",
    "$\\beq\n",
    "\\rrr_\\mathrm{cam} &= \\rrr_\\mathrm{target} \n",
    "+  \\left( w_0 + \\frac{w_\\mathrm{\\max} - w_\\mathrm{\\min}}{2}  \\right)\n",
    "\\bbb\n",
    "\\eeq$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f830f-30b7-4ae7-a837-200f354d53ec",
   "metadata": {},
   "source": [
    "**Rendering.**  `threed.render` performs the following:\n",
    "- Call `chooseCameraOrientation` if not specified by user.\n",
    "- Call `chooseCameraPosition` if not specified by user.\n",
    "- Create an ambient light and a directional light.\n",
    "- Create a `pythreejs.Camera` containing the objects to draw.  Attach the directional light to the camera.\n",
    "- Create a `pythreejs.Scene` containing the objects to draw.  Attach the camera to the scene, and attach the ambient light to the scene.\n",
    "- Create a `pythreejs.OrbitControls`.  Attach this to the camera.\n",
    "- Set the camera orientation.  (This must be done after attaching the OrbitControls.)\n",
    "- Create a `pythreejs.Renderer`.  Return this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6315ef65-a8cb-4a63-80e8-09427b32fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions (precision=2,floatmode='fixed',suppress=True)\n",
    "# for pointA,pointB in itertools.combinations (points, 2):\n",
    "#   if np.linalg.norm(pointB - pointA) < 5.01:\n",
    "#     objects.append ( threed.cylinder (pointA, pointB, radius=.2, color='#99FF99') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe4f1e-e1da-4a04-b906-95d918f18ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6cfb61-4d96-400c-922f-573df60bcb4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
